import numpy as np

from webotsgym.env.webotenv import WbtGym
from webotsgym.env.grid.action import WbtActGrid
from webotsgym.env.grid.observation import WbtObsGrid
from webotsgym.config import WbtConfig
from webotsgym.env.reward import WbtRewardGrid

import webotsgym.utils as utils


class WbtGymGrid(WbtGym):
    """Create environment class for the grid action.

    Parameters
    ----------
    seed : integer
        created seed for environment

    action_class : WbtActGrid
        action class for the grid environment

    evaluate_class : WbtRewardGrid
        reward class for the grid environment

    observation_class : WbtObsGrid
        observation class for the grid environment

    The rest of parameters are all the same as for the normal environment.

    """
    def __init__(self, seed=None, gps_target=(1, 1),
                 train=True, evaluate_class=WbtRewardGrid,
                 config: WbtConfig = WbtConfig()):
        """Initialize WbtGymGrid class."""
        config.world_scaling = 0.5
        super(WbtGymGrid, self).__init__(seed=seed,
                                         gps_target=gps_target,
                                         train=train,
                                         action_class=WbtActGrid,
                                         evaluate_class=evaluate_class,
                                         observation_class=WbtObsGrid,
                                         config=config)
        len_ = int(config.world_size * config.world_scaling) * 2 + 1
        self.visited_count = np.zeros((len_, len_))

    def step(self, action):
        """Perform action on environment.

        Safety in grid world is handled by not allowing actions in a direction
        where zero possible steps are possible.

        Parameters
        ----------
        action : int (0, 1, 2, 3)
            Action from RL agent to be send via external controller. The action
            from the agent is mapped via WbtActGrid.

        Returns
        -------
        observation : np.ndarray
            Current webots state information, handled in the observation_class.
        reward : float
            Reward generated by applying the agent's action. This is handled in
            the evaluate_class.
        done : bool
            Flag whether environment run is finished. This is handled in the
            evaluate_class.
        dict
            Empty info dict.

        """
        if self.action_class.type != "grid":
            raise TypeError("WebotsGrid need grid action class.")

        self.state.action_denied = 0
        if self.observation_class.lidar[action] < 1:  # safety :D
            self.state.action_denied = 1
        else:
            action = self.action_class.map(action)
            self.com.send_grid_move(action)

        # logging, printing
        self.distances.append(self.get_target_distance())
        self._update_history()
        self.visited_count[self.gps_actual_scaled] += 1

        distance_traveled = 0
        if self.steps_in_run > 1:
            gps_old = self.history[-2].gps_actual
            distance_traveled = utils.euklidian_distance(gps_old,
                                                         self.gps_actual)

        if distance_traveled > 0 and distance_traveled < 0.4:
            print(self.com.packet.sim_time)
            raise RuntimeError("Error in Grid world!")

        reward = self.calc_reward()
        self.rewards.append(reward)
        done = self.check_done()

        return self.observation, reward, done, {}

    def reset(self, seed=None):
        """Reset environment as in WbtGym.

        Additionally reinitialize visited_count.
        """
        super().reset(seed)

        len_ = int(self.config.world_size * self.config.world_scaling) * 2 + 1
        self.visited_count = np.zeros((len_, len_))
        return self.observation

    @property
    def gps_visited_count(self):
        """Get visited count."""
        return self.visited_count[self.gps_actual_scaled]

    @property
    def gps_actual_scaled(self):
        """Get actual gps scladed."""
        return tuple(np.round(0.5 + np.array(self.gps_actual) * 2).astype(int))
