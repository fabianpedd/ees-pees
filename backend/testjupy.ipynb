{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import webotsgym as wg\n",
    "\n",
    "from webotsgym.config import WebotConfig\n",
    "from webotsgym.environment import WebotsEnv\n",
    "from webotsgym.evaluate import EvaluateMats\n",
    "\n",
    "import gym\n",
    "import stable_baselines\n",
    "from stable_baselines import A2C, ACER, ACKTR, DQN, DDPG, SAC, PPO1, PPO2, TD3, TRPO\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.common.policies import MlpPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepting on Port:  10201\n",
      "sending: env\n"
     ]
    }
   ],
   "source": [
    "config = WebotConfig()\n",
    "config.fast_simulation = False\n",
    "config.reset_after = 2500\n",
    "env = WebotsEnv(train=True, evaluate_class=EvaluateMats, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/distributions.py:326: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/distributions.py:327: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/ppo1/pposgd_simple.py:153: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/ppo1/pposgd_simple.py:163: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:241: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:242: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/ppo1/pposgd_simple.py:191: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "********** Iteration 0 ************\n",
      "TIME FOR RESET========= 17.256587743759155\n",
      "=========resetting with seed:  49793\n",
      "sending: reset\n",
      "Reward ( 250 )\t -10.490601121519585\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00540 |      -0.02196 |      2.77e+04 |       0.00085 |       2.19646\n",
      "     -0.01047 |      -0.02193 |      2.70e+04 |       0.00391 |       2.19345\n",
      "     -0.02058 |      -0.02186 |      2.67e+04 |       0.01161 |       2.18573\n",
      "     -0.02277 |      -0.02182 |      2.65e+04 |       0.01529 |       2.18199\n",
      "Evaluating losses...\n",
      "     -0.02423 |      -0.02183 |      2.64e+04 |       0.01401 |       2.18328\n",
      "----------------------------------\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 0            |\n",
      "| TimeElapsed     | 3.94         |\n",
      "| TimestepsSoFar  | 256          |\n",
      "| ev_tdlam_before | -0.00251     |\n",
      "| loss_ent        | 2.1832805    |\n",
      "| loss_kl         | 0.014007281  |\n",
      "| loss_pol_entpen | -0.021832803 |\n",
      "| loss_pol_surr   | -0.024226718 |\n",
      "| loss_vf_loss    | 26444.691    |\n",
      "----------------------------------\n",
      "********** Iteration 1 ************\n",
      "Reward ( 500 )\t -10.489901129409512\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00058 |      -0.02185 |      2.78e+04 |       0.00043 |       2.18451\n",
      "     -0.00667 |      -0.02188 |      2.77e+04 |       0.00245 |       2.18848\n",
      "     -0.00756 |      -0.02190 |      2.75e+04 |       0.00627 |       2.18958\n",
      "     -0.01019 |      -0.02187 |      2.74e+04 |       0.01002 |       2.18727\n",
      "Evaluating losses...\n",
      "     -0.01237 |      -0.02184 |      2.74e+04 |       0.01098 |       2.18415\n",
      "----------------------------------\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 0            |\n",
      "| TimeElapsed     | 4.37         |\n",
      "| TimestepsSoFar  | 512          |\n",
      "| ev_tdlam_before | 0.000267     |\n",
      "| loss_ent        | 2.1841507    |\n",
      "| loss_kl         | 0.010975182  |\n",
      "| loss_pol_entpen | -0.021841504 |\n",
      "| loss_pol_surr   | -0.012367368 |\n",
      "| loss_vf_loss    | 27353.254    |\n",
      "----------------------------------\n",
      "********** Iteration 2 ************\n",
      "Reward ( 750 )\t -10.490663664009713\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00055 |      -0.02183 |      2.77e+04 |      7.31e-05 |       2.18305\n",
      "     -0.00156 |      -0.02178 |      2.76e+04 |       0.00098 |       2.17832\n",
      "     -0.00565 |      -0.02172 |      2.75e+04 |       0.00350 |       2.17178\n",
      "     -0.00592 |      -0.02168 |      2.75e+04 |       0.00598 |       2.16841\n",
      "Evaluating losses...\n",
      "     -0.00926 |      -0.02171 |      2.74e+04 |       0.00563 |       2.17070\n",
      "----------------------------------\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 0            |\n",
      "| TimeElapsed     | 4.9          |\n",
      "| TimestepsSoFar  | 768          |\n",
      "| ev_tdlam_before | -4.2e-05     |\n",
      "| loss_ent        | 2.170703     |\n",
      "| loss_kl         | 0.0056298478 |\n",
      "| loss_pol_entpen | -0.02170703  |\n",
      "| loss_pol_surr   | -0.009255495 |\n",
      "| loss_vf_loss    | 27394.547    |\n",
      "----------------------------------\n",
      "********** Iteration 3 ************\n",
      "Reward ( 1000 )\t -10.489657104020994\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00178 |      -0.02172 |      2.77e+04 |       0.00019 |       2.17240\n",
      "     -0.00183 |      -0.02174 |      2.76e+04 |       0.00058 |       2.17442\n",
      "     -0.00645 |      -0.02173 |      2.75e+04 |       0.00156 |       2.17334\n",
      "     -0.00959 |      -0.02170 |      2.74e+04 |       0.00390 |       2.16989\n",
      "Evaluating losses...\n",
      "     -0.01214 |      -0.02166 |      2.74e+04 |       0.00550 |       2.16596\n",
      "----------------------------------\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 0            |\n",
      "| TimeElapsed     | 5.32         |\n",
      "| TimestepsSoFar  | 1024         |\n",
      "| ev_tdlam_before | 0.000238     |\n",
      "| loss_ent        | 2.165956     |\n",
      "| loss_kl         | 0.0054960186 |\n",
      "| loss_pol_entpen | -0.02165956  |\n",
      "| loss_pol_surr   | -0.012137089 |\n",
      "| loss_vf_loss    | 27385.898    |\n",
      "----------------------------------\n",
      "********** Iteration 4 ************\n",
      "Reward ( 1250 )\t -10.489586243447013\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00201 |      -0.02163 |      2.76e+04 |       0.00013 |       2.16307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     -0.00396 |      -0.02162 |      2.76e+04 |       0.00050 |       2.16152\n",
      "     -0.01230 |      -0.02162 |      2.75e+04 |       0.00251 |       2.16249\n",
      "     -0.01885 |      -0.02159 |      2.74e+04 |       0.00810 |       2.15874\n",
      "Evaluating losses...\n",
      "     -0.02300 |      -0.02152 |      2.74e+04 |       0.01291 |       2.15249\n",
      "----------------------------------\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 0            |\n",
      "| TimeElapsed     | 5.86         |\n",
      "| TimestepsSoFar  | 1280         |\n",
      "| ev_tdlam_before | -1.08e-05    |\n",
      "| loss_ent        | 2.1524878    |\n",
      "| loss_kl         | 0.012909558  |\n",
      "| loss_pol_entpen | -0.021524874 |\n",
      "| loss_pol_surr   | -0.022995377 |\n",
      "| loss_vf_loss    | 27364.174    |\n",
      "----------------------------------\n",
      "********** Iteration 5 ************\n",
      "Reward ( 1500 )\t -10.489172987061245\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00027 |      -0.02150 |      2.76e+04 |       0.00017 |       2.15007\n",
      "     -0.00460 |      -0.02140 |      2.75e+04 |       0.00152 |       2.13990\n",
      "     -0.00683 |      -0.02126 |      2.74e+04 |       0.00502 |       2.12571\n",
      "     -0.00940 |      -0.02124 |      2.74e+04 |       0.00720 |       2.12361\n",
      "Evaluating losses...\n",
      "     -0.01111 |      -0.02128 |      2.73e+04 |       0.00722 |       2.12809\n",
      "----------------------------------\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 0            |\n",
      "| TimeElapsed     | 6.33         |\n",
      "| TimestepsSoFar  | 1536         |\n",
      "| ev_tdlam_before | 2.74e-06     |\n",
      "| loss_ent        | 2.128095     |\n",
      "| loss_kl         | 0.007224738  |\n",
      "| loss_pol_entpen | -0.021280948 |\n",
      "| loss_pol_surr   | -0.011105321 |\n",
      "| loss_vf_loss    | 27339.22     |\n",
      "----------------------------------\n",
      "********** Iteration 6 ************\n",
      "Reward ( 1750 )\t -10.488872915179197\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00159 |      -0.02131 |      2.75e+04 |       0.00014 |       2.13121\n",
      "     -0.01162 |      -0.02133 |      2.75e+04 |       0.00161 |       2.13326\n",
      "     -0.01200 |      -0.02129 |      2.74e+04 |       0.00394 |       2.12874\n",
      "     -0.01581 |      -0.02121 |      2.74e+04 |       0.00603 |       2.12086\n",
      "Evaluating losses...\n",
      "     -0.01929 |      -0.02115 |      2.73e+04 |       0.00719 |       2.11511\n",
      "----------------------------------\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 0            |\n",
      "| TimeElapsed     | 6.77         |\n",
      "| TimestepsSoFar  | 1792         |\n",
      "| ev_tdlam_before | 0.000938     |\n",
      "| loss_ent        | 2.115107     |\n",
      "| loss_kl         | 0.0071934783 |\n",
      "| loss_pol_entpen | -0.02115107  |\n",
      "| loss_pol_surr   | -0.019285904 |\n",
      "| loss_vf_loss    | 27313.996    |\n",
      "----------------------------------\n",
      "********** Iteration 7 ************\n",
      "Reward ( 2000 )\t -10.489147526836543\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00076 |      -0.02112 |      2.75e+04 |      7.43e-05 |       2.11195\n",
      "     -0.00636 |      -0.02109 |      2.74e+04 |       0.00121 |       2.10935\n",
      "     -0.01592 |      -0.02109 |      2.74e+04 |       0.00505 |       2.10876\n",
      "     -0.01633 |      -0.02113 |      2.73e+04 |       0.00924 |       2.11274\n",
      "Evaluating losses...\n",
      "     -0.01634 |      -0.02119 |      2.73e+04 |       0.01053 |       2.11860\n",
      "----------------------------------\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 0            |\n",
      "| TimeElapsed     | 7.24         |\n",
      "| TimestepsSoFar  | 2048         |\n",
      "| ev_tdlam_before | -4.48e-05    |\n",
      "| loss_ent        | 2.1186023    |\n",
      "| loss_kl         | 0.0105318725 |\n",
      "| loss_pol_entpen | -0.02118602  |\n",
      "| loss_pol_surr   | -0.016337026 |\n",
      "| loss_vf_loss    | 27297.824    |\n",
      "----------------------------------\n",
      "********** Iteration 8 ************\n",
      "Reward ( 2250 )\t -10.48833876671965\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00053 |      -0.02121 |      2.75e+04 |      9.83e-05 |       2.12140\n",
      "     -0.00371 |      -0.02128 |      2.74e+04 |       0.00057 |       2.12770\n",
      "     -0.00515 |      -0.02130 |      2.74e+04 |       0.00156 |       2.13048\n",
      "     -0.00519 |      -0.02130 |      2.73e+04 |       0.00303 |       2.12977\n",
      "Evaluating losses...\n",
      "     -0.00804 |      -0.02127 |      2.73e+04 |       0.00399 |       2.12750\n",
      "----------------------------------\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 0            |\n",
      "| TimeElapsed     | 7.66         |\n",
      "| TimestepsSoFar  | 2304         |\n",
      "| ev_tdlam_before | 3.26e-05     |\n",
      "| loss_ent        | 2.1274986    |\n",
      "| loss_kl         | 0.0039862213 |\n",
      "| loss_pol_entpen | -0.021274984 |\n",
      "| loss_pol_surr   | -0.008040759 |\n",
      "| loss_vf_loss    | 27275.504    |\n",
      "----------------------------------\n",
      "********** Iteration 9 ************\n",
      "Reward ( 2500 )\t -10.488222232155723\n",
      "TIME FOR RESET========= 7.987710237503052\n",
      "=========resetting with seed:  57781\n",
      "sending: reset\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00034 |      -0.02124 |      2.46e+04 |       0.00012 |       2.12376\n",
      "     -0.00632 |      -0.02115 |      2.46e+04 |       0.00091 |       2.11507\n",
      "     -0.00838 |      -0.02109 |      2.46e+04 |       0.00220 |       2.10947\n",
      "     -0.01174 |      -0.02115 |      2.45e+04 |       0.00249 |       2.11538\n",
      "Evaluating losses...\n",
      "     -0.01373 |      -0.02115 |      2.45e+04 |       0.00341 |       2.11546\n",
      "----------------------------------\n",
      "| EpLenMean       | 2.5e+03      |\n",
      "| EpRewMean       | -2.62e+04    |\n",
      "| EpThisIter      | 1            |\n",
      "| EpisodesSoFar   | 1            |\n",
      "| TimeElapsed     | 11.5         |\n",
      "| TimestepsSoFar  | 2560         |\n",
      "| ev_tdlam_before | -6.2e-06     |\n",
      "| loss_ent        | 2.1154573    |\n",
      "| loss_kl         | 0.0034064618 |\n",
      "| loss_pol_entpen | -0.021154571 |\n",
      "| loss_pol_surr   | -0.013726626 |\n",
      "| loss_vf_loss    | 24493.277    |\n",
      "----------------------------------\n",
      "********** Iteration 10 ************\n",
      "Reward ( 2750 )\t -10.615637033347614\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00175 |      -0.02111 |      2.81e+04 |       0.00011 |       2.11126\n",
      "     -0.00756 |      -0.02101 |      2.80e+04 |       0.00140 |       2.10148\n",
      "     -0.01086 |      -0.02093 |      2.80e+04 |       0.00387 |       2.09267\n",
      "     -0.01105 |      -0.02103 |      2.80e+04 |       0.00434 |       2.10290\n",
      "Evaluating losses...\n",
      "     -0.01205 |      -0.02111 |      2.79e+04 |       0.00441 |       2.11057\n",
      "----------------------------------\n",
      "| EpLenMean       | 2.5e+03      |\n",
      "| EpRewMean       | -2.62e+04    |\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 1            |\n",
      "| TimeElapsed     | 11.9         |\n",
      "| TimestepsSoFar  | 2816         |\n",
      "| ev_tdlam_before | -1.81e-05    |\n",
      "| loss_ent        | 2.11057      |\n",
      "| loss_kl         | 0.004405824  |\n",
      "| loss_pol_entpen | -0.021105697 |\n",
      "| loss_pol_surr   | -0.012053268 |\n",
      "| loss_vf_loss    | 27929.064    |\n",
      "----------------------------------\n",
      "********** Iteration 11 ************\n",
      "Reward ( 3000 )\t -10.613771734872028\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00058 |      -0.02109 |      2.81e+04 |      2.91e-05 |       2.10889\n",
      "     -0.00073 |      -0.02104 |      2.80e+04 |       0.00024 |       2.10351\n",
      "     -0.00223 |      -0.02095 |      2.80e+04 |       0.00089 |       2.09470\n",
      "     -0.00303 |      -0.02089 |      2.79e+04 |       0.00157 |       2.08884\n",
      "Evaluating losses...\n",
      "     -0.00370 |      -0.02090 |      2.79e+04 |       0.00147 |       2.09037\n",
      "-----------------------------------\n",
      "| EpLenMean       | 2.5e+03       |\n",
      "| EpRewMean       | -2.62e+04     |\n",
      "| EpThisIter      | 0             |\n",
      "| EpisodesSoFar   | 1             |\n",
      "| TimeElapsed     | 12.5          |\n",
      "| TimestepsSoFar  | 3072          |\n",
      "| ev_tdlam_before | -3.22e-06     |\n",
      "| loss_ent        | 2.0903707     |\n",
      "| loss_kl         | 0.0014733946  |\n",
      "| loss_pol_entpen | -0.020903707  |\n",
      "| loss_pol_surr   | -0.0036955178 |\n",
      "| loss_vf_loss    | 27913.41      |\n",
      "-----------------------------------\n",
      "********** Iteration 12 ************\n",
      "Reward ( 3250 )\t -10.607770360356094\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0.00037 |      -0.02090 |      2.80e+04 |      2.18e-05 |       2.09023\n",
      "     -0.00301 |      -0.02089 |      2.80e+04 |       0.00018 |       2.08887\n",
      "     -0.00564 |      -0.02085 |      2.79e+04 |       0.00082 |       2.08468\n",
      "     -0.00680 |      -0.02080 |      2.79e+04 |       0.00215 |       2.07984\n",
      "Evaluating losses...\n",
      "     -0.00777 |      -0.02077 |      2.79e+04 |       0.00302 |       2.07691\n",
      "----------------------------------\n",
      "| EpLenMean       | 2.5e+03      |\n",
      "| EpRewMean       | -2.62e+04    |\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 1            |\n",
      "| TimeElapsed     | 13           |\n",
      "| TimestepsSoFar  | 3328         |\n",
      "| ev_tdlam_before | 5.76e-05     |\n",
      "| loss_ent        | 2.07691      |\n",
      "| loss_kl         | 0.0030247355 |\n",
      "| loss_pol_entpen | -0.020769099 |\n",
      "| loss_pol_surr   | -0.00777022  |\n",
      "| loss_vf_loss    | 27873.59     |\n",
      "----------------------------------\n",
      "********** Iteration 13 ************\n",
      "Reward ( 3500 )\t -10.602271316562431\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00056 |      -0.02075 |      2.79e+04 |      2.66e-05 |       2.07523\n",
      "     -0.00435 |      -0.02074 |      2.79e+04 |       0.00032 |       2.07364\n",
      "     -0.00516 |      -0.02076 |      2.79e+04 |       0.00119 |       2.07608\n",
      "     -0.00568 |      -0.02076 |      2.79e+04 |       0.00215 |       2.07558\n",
      "Evaluating losses...\n",
      "     -0.00629 |      -0.02074 |      2.78e+04 |       0.00255 |       2.07366\n",
      "-----------------------------------\n",
      "| EpLenMean       | 2.5e+03       |\n",
      "| EpRewMean       | -2.62e+04     |\n",
      "| EpThisIter      | 0             |\n",
      "| EpisodesSoFar   | 1             |\n",
      "| TimeElapsed     | 13.5          |\n",
      "| TimestepsSoFar  | 3584          |\n",
      "| ev_tdlam_before | 7.33e-06      |\n",
      "| loss_ent        | 2.073657      |\n",
      "| loss_kl         | 0.0025509908  |\n",
      "| loss_pol_entpen | -0.020736568  |\n",
      "| loss_pol_surr   | -0.0062907124 |\n",
      "| loss_vf_loss    | 27833.734     |\n",
      "-----------------------------------\n",
      "********** Iteration 14 ************\n",
      "Reward ( 3750 )\t -10.602501742745497\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00054 |      -0.02072 |      2.79e+04 |      3.46e-05 |       2.07178\n",
      "     -0.00382 |      -0.02063 |      2.79e+04 |       0.00037 |       2.06289\n",
      "     -0.00613 |      -0.02051 |      2.79e+04 |       0.00134 |       2.05082\n",
      "     -0.00652 |      -0.02048 |      2.78e+04 |       0.00193 |       2.04776\n",
      "Evaluating losses...\n",
      "     -0.00694 |      -0.02053 |      2.78e+04 |       0.00170 |       2.05263\n",
      "----------------------------------\n",
      "| EpLenMean       | 2.5e+03      |\n",
      "| EpRewMean       | -2.62e+04    |\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 1            |\n",
      "| TimeElapsed     | 14           |\n",
      "| TimestepsSoFar  | 3840         |\n",
      "| ev_tdlam_before | -2.62e-06    |\n",
      "| loss_ent        | 2.0526333    |\n",
      "| loss_kl         | 0.001702495  |\n",
      "| loss_pol_entpen | -0.020526335 |\n",
      "| loss_pol_surr   | -0.006939579 |\n",
      "| loss_vf_loss    | 27833.53     |\n",
      "----------------------------------\n",
      "********** Iteration 15 ************\n",
      "Reward ( 4000 )\t -10.602400939134236\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "    -8.09e-05 |      -0.02055 |      2.79e+04 |      4.45e-05 |       2.05472\n",
      "     -0.00089 |      -0.02067 |      2.79e+04 |       0.00053 |       2.06715\n",
      "     -0.00152 |      -0.02072 |      2.79e+04 |       0.00090 |       2.07180\n",
      "     -0.00202 |      -0.02063 |      2.78e+04 |       0.00049 |       2.06336\n",
      "Evaluating losses...\n",
      "     -0.00254 |      -0.02059 |      2.78e+04 |       0.00037 |       2.05901\n",
      "-----------------------------------\n",
      "| EpLenMean       | 2.5e+03       |\n",
      "| EpRewMean       | -2.62e+04     |\n",
      "| EpThisIter      | 0             |\n",
      "| EpisodesSoFar   | 1             |\n",
      "| TimeElapsed     | 14.4          |\n",
      "| TimestepsSoFar  | 4096          |\n",
      "| ev_tdlam_before | -1.43e-06     |\n",
      "| loss_ent        | 2.05901       |\n",
      "| loss_kl         | 0.00036797914 |\n",
      "| loss_pol_entpen | -0.0205901    |\n",
      "| loss_pol_surr   | -0.0025444701 |\n",
      "| loss_vf_loss    | 27834.6       |\n",
      "-----------------------------------\n",
      "********** Iteration 16 ************\n",
      "Reward ( 4250 )\t -10.600734172925387\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "    -2.57e-05 |      -0.02063 |      2.79e+04 |      5.99e-06 |       2.06344\n",
      "     -0.00186 |      -0.02066 |      2.79e+04 |      7.23e-05 |       2.06582\n",
      "     -0.00304 |      -0.02069 |      2.79e+04 |       0.00023 |       2.06857\n",
      "     -0.00357 |      -0.02069 |      2.78e+04 |       0.00040 |       2.06902\n",
      "Evaluating losses...\n",
      "     -0.00375 |      -0.02069 |      2.78e+04 |       0.00050 |       2.06877\n",
      "-----------------------------------\n",
      "| EpLenMean       | 2.5e+03       |\n",
      "| EpRewMean       | -2.62e+04     |\n",
      "| EpThisIter      | 0             |\n",
      "| EpisodesSoFar   | 1             |\n",
      "| TimeElapsed     | 14.8          |\n",
      "| TimestepsSoFar  | 4352          |\n",
      "| ev_tdlam_before | 2.03e-06      |\n",
      "| loss_ent        | 2.0687683     |\n",
      "| loss_kl         | 0.0004990236  |\n",
      "| loss_pol_entpen | -0.020687683  |\n",
      "| loss_pol_surr   | -0.0037527196 |\n",
      "| loss_vf_loss    | 27832.158     |\n",
      "-----------------------------------\n",
      "********** Iteration 17 ************\n",
      "Reward ( 4500 )\t -10.599360499131606\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00023 |      -0.02067 |      2.79e+04 |      9.41e-06 |       2.06695\n",
      "     -0.00196 |      -0.02071 |      2.79e+04 |       0.00011 |       2.07133\n",
      "     -0.00156 |      -0.02075 |      2.78e+04 |       0.00027 |       2.07465\n",
      "     -0.00168 |      -0.02075 |      2.78e+04 |       0.00035 |       2.07538\n",
      "Evaluating losses...\n",
      "     -0.00188 |      -0.02075 |      2.78e+04 |       0.00037 |       2.07495\n",
      "-----------------------------------\n",
      "| EpLenMean       | 2.5e+03       |\n",
      "| EpRewMean       | -2.62e+04     |\n",
      "| EpThisIter      | 0             |\n",
      "| EpisodesSoFar   | 1             |\n",
      "| TimeElapsed     | 15.2          |\n",
      "| TimestepsSoFar  | 4608          |\n",
      "| ev_tdlam_before | -4.65e-06     |\n",
      "| loss_ent        | 2.074954      |\n",
      "| loss_kl         | 0.0003660961  |\n",
      "| loss_pol_entpen | -0.020749537  |\n",
      "| loss_pol_surr   | -0.0018830337 |\n",
      "| loss_vf_loss    | 27831.148     |\n",
      "-----------------------------------\n",
      "********** Iteration 18 ************\n",
      "Reward ( 4750 )\t -10.595841308268483\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     4.90e-05 |      -0.02075 |      2.79e+04 |      5.43e-07 |       2.07450\n",
      "    -5.99e-05 |      -0.02076 |      2.78e+04 |      8.24e-06 |       2.07550\n",
      "     -0.00100 |      -0.02077 |      2.78e+04 |      2.99e-05 |       2.07686\n",
      "     -0.00126 |      -0.02078 |      2.78e+04 |      6.87e-05 |       2.07776\n",
      "Evaluating losses...\n",
      "     -0.00139 |      -0.02078 |      2.78e+04 |      9.41e-05 |       2.07808\n",
      "-----------------------------------\n",
      "| EpLenMean       | 2.5e+03       |\n",
      "| EpRewMean       | -2.62e+04     |\n",
      "| EpThisIter      | 0             |\n",
      "| EpisodesSoFar   | 1             |\n",
      "| TimeElapsed     | 15.7          |\n",
      "| TimestepsSoFar  | 4864          |\n",
      "| ev_tdlam_before | 2.98e-06      |\n",
      "| loss_ent        | 2.0780828     |\n",
      "| loss_kl         | 9.408622e-05  |\n",
      "| loss_pol_entpen | -0.020780828  |\n",
      "| loss_pol_surr   | -0.0013871193 |\n",
      "| loss_vf_loss    | 27828.205     |\n",
      "-----------------------------------\n",
      "********** Iteration 19 ************\n",
      "Reward ( 5000 )\t -10.595270389941957\n",
      "TIME FOR RESET========= 7.852675676345825\n",
      "=========resetting with seed:  97\n",
      "sending: reset\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     7.91e-06 |      -0.02076 |      2.49e+04 |      1.62e-07 |       2.07557\n",
      "     -0.00011 |      -0.02075 |      2.49e+04 |      1.30e-06 |       2.07527\n",
      "     -0.00029 |      -0.02075 |      2.49e+04 |      4.61e-06 |       2.07455\n",
      "     -0.00034 |      -0.02074 |      2.49e+04 |      1.02e-05 |       2.07376\n",
      "Evaluating losses...\n",
      "     -0.00035 |      -0.02073 |      2.49e+04 |      1.27e-05 |       2.07343\n",
      "------------------------------------\n",
      "| EpLenMean       | 2.5e+03        |\n",
      "| EpRewMean       | -2.64e+04      |\n",
      "| EpThisIter      | 1              |\n",
      "| EpisodesSoFar   | 2              |\n",
      "| TimeElapsed     | 19.3           |\n",
      "| TimestepsSoFar  | 5120           |\n",
      "| ev_tdlam_before | 1.19e-06       |\n",
      "| loss_ent        | 2.073425       |\n",
      "| loss_kl         | 1.27213825e-05 |\n",
      "| loss_pol_entpen | -0.02073425    |\n",
      "| loss_pol_surr   | -0.00035045668 |\n",
      "| loss_vf_loss    | 24929.254      |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "time_steps = 4999\n",
    "model_name = \"Webots2\"\n",
    "\n",
    "model = PPO1(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=time_steps, log_interval=100)\n",
    "model.save(\"models/{}\".format(model_name))\n",
    "\n",
    "# model = PPO1.load(\"models/{}\".format('DQN_WebotFakeMini_TRPO_pj1_nReward2_200000'))\n",
    "# env = MyEnv()\n",
    "# obs = env.reset()\n",
    "\n",
    "# env.render()\n",
    "# done = False\n",
    "# max_num_steps = 100\n",
    "# time = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
