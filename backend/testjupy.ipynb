{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import environment\n",
    "import importlib\n",
    "from config import WebotConfig\n",
    "\n",
    "from evaluate import EvaluateMats\n",
    "\n",
    "import gym\n",
    "import stable_baselines\n",
    "from stable_baselines import A2C, ACER, ACKTR, DQN, DDPG, SAC, PPO1, PPO2, TD3, TRPO\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.common.policies import MlpPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepting on Port:  10201\n",
      "sending: env\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(environment)\n",
    "config = WebotConfig()\n",
    "config.fast_simulation = False\n",
    "config.reset_after = 500\n",
    "env = environment.WebotsEnv(train=True, evaluate_class=EvaluateMats, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/distributions.py:326: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/distributions.py:327: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/ppo1/pposgd_simple.py:153: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/ppo1/pposgd_simple.py:163: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:241: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:242: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/ppo1/pposgd_simple.py:191: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/pj/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "********** Iteration 0 ************\n",
      "TIME FOR RESET========= 17.155280828475952\n",
      "=========resetting with seed:  25534\n",
      "sending: reset\n",
      "Reward ( 250 )\t -10.440596086791324\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00066 |      -0.02196 |      2.75e+04 |       0.00085 |       2.19631\n",
      "     -0.01669 |      -0.02192 |      2.70e+04 |       0.00497 |       2.19217\n",
      "     -0.02334 |      -0.02184 |      2.65e+04 |       0.01314 |       2.18421\n",
      "     -0.02611 |      -0.02183 |      2.63e+04 |       0.01471 |       2.18291\n",
      "Evaluating losses...\n",
      "     -0.02852 |      -0.02186 |      2.63e+04 |       0.01117 |       2.18641\n",
      "---------------------------------\n",
      "| EpThisIter      | 0           |\n",
      "| EpisodesSoFar   | 0           |\n",
      "| TimeElapsed     | 4.06        |\n",
      "| TimestepsSoFar  | 256         |\n",
      "| ev_tdlam_before | 0.00457     |\n",
      "| loss_ent        | 2.1864083   |\n",
      "| loss_kl         | 0.011174168 |\n",
      "| loss_pol_entpen | -0.02186408 |\n",
      "| loss_pol_surr   | -0.02851545 |\n",
      "| loss_vf_loss    | 26255.877   |\n",
      "---------------------------------\n",
      "********** Iteration 1 ************\n",
      "Reward ( 500 )\t -10.439901101144732\n",
      "TIME FOR RESET========= 4.322446584701538\n",
      "=========resetting with seed:  29856\n",
      "sending: reset\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "    -1.04e-06 |      -0.02185 |      2.61e+04 |      8.16e-05 |       2.18515\n",
      "     -0.01462 |      -0.02181 |      2.59e+04 |       0.00106 |       2.18072\n",
      "     -0.03248 |      -0.02170 |      2.58e+04 |       0.00599 |       2.16968\n",
      "     -0.04123 |      -0.02161 |      2.57e+04 |       0.01367 |       2.16052\n",
      "Evaluating losses...\n",
      "     -0.04384 |      -0.02160 |      2.56e+04 |       0.01712 |       2.16015\n",
      "----------------------------------\n",
      "| EpLenMean       | 498          |\n",
      "| EpRewMean       | -5.2e+03     |\n",
      "| EpThisIter      | 1            |\n",
      "| EpisodesSoFar   | 1            |\n",
      "| TimeElapsed     | 7.7          |\n",
      "| TimestepsSoFar  | 512          |\n",
      "| ev_tdlam_before | -0.00147     |\n",
      "| loss_ent        | 2.1601453    |\n",
      "| loss_kl         | 0.017124783  |\n",
      "| loss_pol_entpen | -0.021601453 |\n",
      "| loss_pol_surr   | -0.04384076  |\n",
      "| loss_vf_loss    | 25613.021    |\n",
      "----------------------------------\n",
      "********** Iteration 2 ************\n",
      "Reward ( 750 )\t -10.90925052158709\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00072 |      -0.02152 |      3.01e+04 |      4.52e-05 |       2.15169\n",
      "     -0.00169 |      -0.02159 |      3.00e+04 |       0.00093 |       2.15908\n",
      "     -0.01138 |      -0.02171 |      2.99e+04 |       0.00502 |       2.17061\n",
      "     -0.01534 |      -0.02175 |      2.98e+04 |       0.00914 |       2.17509\n",
      "Evaluating losses...\n",
      "     -0.01777 |      -0.02175 |      2.97e+04 |       0.01071 |       2.17452\n",
      "----------------------------------\n",
      "| EpLenMean       | 498          |\n",
      "| EpRewMean       | -5.2e+03     |\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 1            |\n",
      "| TimeElapsed     | 8.16         |\n",
      "| TimestepsSoFar  | 768          |\n",
      "| ev_tdlam_before | 0.000287     |\n",
      "| loss_ent        | 2.1745164    |\n",
      "| loss_kl         | 0.010713641  |\n",
      "| loss_pol_entpen | -0.021745164 |\n",
      "| loss_pol_surr   | -0.017769974 |\n",
      "| loss_vf_loss    | 29716.623    |\n",
      "----------------------------------\n",
      "********** Iteration 3 ************\n",
      "Reward ( 1000 )\t -10.904557892311201\n",
      "TIME FOR RESET========= 4.107637882232666\n",
      "=========resetting with seed:  33964\n",
      "sending: reset\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00123 |      -0.02181 |      2.75e+04 |       0.00010 |       2.18148\n",
      "     -0.00312 |      -0.02185 |      2.74e+04 |       0.00136 |       2.18491\n",
      "     -0.00776 |      -0.02189 |      2.73e+04 |       0.00669 |       2.18943\n",
      "     -0.00857 |      -0.02189 |      2.72e+04 |       0.01038 |       2.18859\n",
      "Evaluating losses...\n",
      "     -0.01163 |      -0.02187 |      2.72e+04 |       0.00937 |       2.18667\n",
      "----------------------------------\n",
      "| EpLenMean       | 498          |\n",
      "| EpRewMean       | -5.32e+03    |\n",
      "| EpThisIter      | 1            |\n",
      "| EpisodesSoFar   | 2            |\n",
      "| TimeElapsed     | 11.8         |\n",
      "| TimestepsSoFar  | 1024         |\n",
      "| ev_tdlam_before | 0.000186     |\n",
      "| loss_ent        | 2.186667     |\n",
      "| loss_kl         | 0.009372802  |\n",
      "| loss_pol_entpen | -0.021866672 |\n",
      "| loss_pol_surr   | -0.011634385 |\n",
      "| loss_vf_loss    | 27191.291    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Iteration 4 ************\n",
      "Reward ( 1250 )\t -10.980598383176186\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00280 |      -0.02181 |      3.03e+04 |       0.00053 |       2.18143\n",
      "     -0.01194 |      -0.02169 |      3.02e+04 |       0.00634 |       2.16899\n",
      "     -0.01724 |      -0.02162 |      3.01e+04 |       0.01132 |       2.16221\n",
      "     -0.02003 |      -0.02167 |      3.00e+04 |       0.01071 |       2.16679\n",
      "Evaluating losses...\n",
      "     -0.02199 |      -0.02170 |      3.00e+04 |       0.01014 |       2.17029\n",
      "----------------------------------\n",
      "| EpLenMean       | 498          |\n",
      "| EpRewMean       | -5.32e+03    |\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 2            |\n",
      "| TimeElapsed     | 12.3         |\n",
      "| TimestepsSoFar  | 1280         |\n",
      "| ev_tdlam_before | 0.000139     |\n",
      "| loss_ent        | 2.17029      |\n",
      "| loss_kl         | 0.010139347  |\n",
      "| loss_pol_entpen | -0.021702899 |\n",
      "| loss_pol_surr   | -0.02199405  |\n",
      "| loss_vf_loss    | 29975.725    |\n",
      "----------------------------------\n",
      "********** Iteration 5 ************\n",
      "Reward ( 1500 )\t -10.979570997908343\n",
      "TIME FOR RESET========= 4.117585182189941\n",
      "=========resetting with seed:  38081\n",
      "sending: reset\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00139 |      -0.02169 |      2.71e+04 |       0.00011 |       2.16878\n",
      "     -0.00170 |      -0.02167 |      2.70e+04 |       0.00042 |       2.16679\n",
      "     -0.00874 |      -0.02163 |      2.70e+04 |       0.00143 |       2.16338\n",
      "     -0.01346 |      -0.02159 |      2.69e+04 |       0.00369 |       2.15865\n",
      "Evaluating losses...\n",
      "     -0.01864 |      -0.02155 |      2.69e+04 |       0.00567 |       2.15475\n",
      "----------------------------------\n",
      "| EpLenMean       | 499          |\n",
      "| EpRewMean       | -5.37e+03    |\n",
      "| EpThisIter      | 1            |\n",
      "| EpisodesSoFar   | 3            |\n",
      "| TimeElapsed     | 16           |\n",
      "| TimestepsSoFar  | 1536         |\n",
      "| ev_tdlam_before | 1.75e-05     |\n",
      "| loss_ent        | 2.1547513    |\n",
      "| loss_kl         | 0.0056662816 |\n",
      "| loss_pol_entpen | -0.021547515 |\n",
      "| loss_pol_surr   | -0.01864316  |\n",
      "| loss_vf_loss    | 26874.95     |\n",
      "----------------------------------\n",
      "********** Iteration 6 ************\n",
      "Reward ( 1750 )\t -10.49526980878954\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00250 |      -0.02150 |      2.76e+04 |       0.00036 |       2.15017\n",
      "     -0.01783 |      -0.02137 |      2.75e+04 |       0.00373 |       2.13654\n",
      "     -0.02403 |      -0.02131 |      2.74e+04 |       0.00894 |       2.13090\n",
      "     -0.02382 |      -0.02135 |      2.74e+04 |       0.01200 |       2.13503\n",
      "Evaluating losses...\n",
      "     -0.02463 |      -0.02137 |      2.73e+04 |       0.01284 |       2.13718\n",
      "----------------------------------\n",
      "| EpLenMean       | 499          |\n",
      "| EpRewMean       | -5.37e+03    |\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 3            |\n",
      "| TimeElapsed     | 16.4         |\n",
      "| TimestepsSoFar  | 1792         |\n",
      "| ev_tdlam_before | -1.19e-06    |\n",
      "| loss_ent        | 2.137175     |\n",
      "| loss_kl         | 0.012844324  |\n",
      "| loss_pol_entpen | -0.021371752 |\n",
      "| loss_pol_surr   | -0.024631917 |\n",
      "| loss_vf_loss    | 27331.83     |\n",
      "----------------------------------\n",
      "********** Iteration 7 ************\n",
      "Reward ( 2000 )\t -10.495587574094818\n",
      "TIME FOR RESET========= 4.119782209396362\n",
      "=========resetting with seed:  42201\n",
      "sending: reset\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00015 |      -0.02142 |      2.50e+04 |       0.00011 |       2.14181\n",
      "     -0.00361 |      -0.02147 |      2.50e+04 |       0.00098 |       2.14668\n",
      "     -0.00777 |      -0.02146 |      2.49e+04 |       0.00271 |       2.14631\n",
      "     -0.00942 |      -0.02144 |      2.49e+04 |       0.00451 |       2.14408\n",
      "Evaluating losses...\n",
      "     -0.01217 |      -0.02144 |      2.49e+04 |       0.00556 |       2.14406\n",
      "----------------------------------\n",
      "| EpLenMean       | 499          |\n",
      "| EpRewMean       | -5.34e+03    |\n",
      "| EpThisIter      | 1            |\n",
      "| EpisodesSoFar   | 4            |\n",
      "| TimeElapsed     | 20.1         |\n",
      "| TimestepsSoFar  | 2048         |\n",
      "| ev_tdlam_before | 2.03e-06     |\n",
      "| loss_ent        | 2.1440568    |\n",
      "| loss_kl         | 0.0055612978 |\n",
      "| loss_pol_entpen | -0.021440566 |\n",
      "| loss_pol_surr   | -0.012165923 |\n",
      "| loss_vf_loss    | 24850.236    |\n",
      "----------------------------------\n",
      "********** Iteration 8 ************\n",
      "Reward ( 2250 )\t -10.999632534536389\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00057 |      -0.02145 |      3.02e+04 |      4.57e-05 |       2.14538\n",
      "     -0.00092 |      -0.02147 |      3.02e+04 |       0.00026 |       2.14664\n",
      "     -0.00445 |      -0.02146 |      3.01e+04 |       0.00130 |       2.14618\n",
      "     -0.00772 |      -0.02147 |      3.01e+04 |       0.00257 |       2.14741\n",
      "Evaluating losses...\n",
      "     -0.01030 |      -0.02149 |      3.00e+04 |       0.00330 |       2.14932\n",
      "----------------------------------\n",
      "| EpLenMean       | 499          |\n",
      "| EpRewMean       | -5.34e+03    |\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 4            |\n",
      "| TimeElapsed     | 20.6         |\n",
      "| TimestepsSoFar  | 2304         |\n",
      "| ev_tdlam_before | 5.96e-08     |\n",
      "| loss_ent        | 2.1493192    |\n",
      "| loss_kl         | 0.0033001145 |\n",
      "| loss_pol_entpen | -0.02149319  |\n",
      "| loss_pol_surr   | -0.010301458 |\n",
      "| loss_vf_loss    | 30028.13     |\n",
      "----------------------------------\n",
      "********** Iteration 9 ************\n",
      "Reward ( 2500 )\t -11.000945781651176\n",
      "TIME FOR RESET========= 4.129554510116577\n",
      "=========resetting with seed:  46331\n",
      "sending: reset\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00058 |      -0.02150 |      2.65e+04 |      7.05e-05 |       2.14958\n",
      "     -0.00599 |      -0.02153 |      2.65e+04 |       0.00078 |       2.15342\n",
      "     -0.00889 |      -0.02155 |      2.64e+04 |       0.00229 |       2.15525\n",
      "     -0.01148 |      -0.02153 |      2.64e+04 |       0.00328 |       2.15264\n",
      "Evaluating losses...\n",
      "     -0.01387 |      -0.02150 |      2.64e+04 |       0.00369 |       2.15035\n",
      "----------------------------------\n",
      "| EpLenMean       | 499          |\n",
      "| EpRewMean       | -5.37e+03    |\n",
      "| EpThisIter      | 1            |\n",
      "| EpisodesSoFar   | 5            |\n",
      "| TimeElapsed     | 24.3         |\n",
      "| TimestepsSoFar  | 2560         |\n",
      "| ev_tdlam_before | -1.19e-06    |\n",
      "| loss_ent        | 2.1503534    |\n",
      "| loss_kl         | 0.0036888937 |\n",
      "| loss_pol_entpen | -0.021503532 |\n",
      "| loss_pol_surr   | -0.013872709 |\n",
      "| loss_vf_loss    | 26369.0      |\n",
      "----------------------------------\n",
      "********** Iteration 10 ************\n",
      "Reward ( 2750 )\t -10.539015909581982\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00096 |      -0.02147 |      2.77e+04 |       0.00010 |       2.14665\n",
      "     -0.00522 |      -0.02134 |      2.76e+04 |       0.00151 |       2.13413\n",
      "     -0.00485 |      -0.02123 |      2.76e+04 |       0.00377 |       2.12317\n",
      "     -0.00611 |      -0.02124 |      2.75e+04 |       0.00355 |       2.12440\n",
      "Evaluating losses...\n",
      "     -0.00849 |      -0.02128 |      2.75e+04 |       0.00283 |       2.12813\n",
      "----------------------------------\n",
      "| EpLenMean       | 499          |\n",
      "| EpRewMean       | -5.37e+03    |\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 5            |\n",
      "| TimeElapsed     | 24.7         |\n",
      "| TimestepsSoFar  | 2816         |\n",
      "| ev_tdlam_before | 1.79e-07     |\n",
      "| loss_ent        | 2.1281257    |\n",
      "| loss_kl         | 0.0028298497 |\n",
      "| loss_pol_entpen | -0.021281254 |\n",
      "| loss_pol_surr   | -0.008493386 |\n",
      "| loss_vf_loss    | 27500.059    |\n",
      "----------------------------------\n",
      "********** Iteration 11 ************\n",
      "Reward ( 3000 )\t -10.538837891040178\n",
      "TIME FOR RESET========= 4.174138784408569\n",
      "=========resetting with seed:  50505\n",
      "sending: reset\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00087 |      -0.02138 |      2.46e+04 |      8.11e-05 |       2.13817\n",
      "     -0.00608 |      -0.02140 |      2.45e+04 |       0.00084 |       2.13983\n",
      "     -0.00796 |      -0.02139 |      2.45e+04 |       0.00212 |       2.13852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     -0.00886 |      -0.02138 |      2.45e+04 |       0.00297 |       2.13755\n",
      "Evaluating losses...\n",
      "     -0.01037 |      -0.02138 |      2.44e+04 |       0.00313 |       2.13844\n",
      "----------------------------------\n",
      "| EpLenMean       | 499          |\n",
      "| EpRewMean       | -5.35e+03    |\n",
      "| EpThisIter      | 1            |\n",
      "| EpisodesSoFar   | 6            |\n",
      "| TimeElapsed     | 28.4         |\n",
      "| TimestepsSoFar  | 3072         |\n",
      "| ev_tdlam_before | 8.76e-05     |\n",
      "| loss_ent        | 2.138442     |\n",
      "| loss_kl         | 0.0031259998 |\n",
      "| loss_pol_entpen | -0.021384418 |\n",
      "| loss_pol_surr   | -0.010371391 |\n",
      "| loss_vf_loss    | 24447.496    |\n",
      "----------------------------------\n",
      "********** Iteration 12 ************\n",
      "Reward ( 3250 )\t -10.486092381992586\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00057 |      -0.02136 |      2.73e+04 |      2.92e-05 |       2.13619\n",
      "     -0.00107 |      -0.02138 |      2.73e+04 |       0.00023 |       2.13788\n",
      "     -0.00340 |      -0.02140 |      2.73e+04 |       0.00080 |       2.14039\n",
      "     -0.00461 |      -0.02145 |      2.72e+04 |       0.00192 |       2.14465\n",
      "Evaluating losses...\n",
      "     -0.00506 |      -0.02146 |      2.72e+04 |       0.00250 |       2.14598\n",
      "-----------------------------------\n",
      "| EpLenMean       | 499           |\n",
      "| EpRewMean       | -5.35e+03     |\n",
      "| EpThisIter      | 0             |\n",
      "| EpisodesSoFar   | 6             |\n",
      "| TimeElapsed     | 28.8          |\n",
      "| TimestepsSoFar  | 3328          |\n",
      "| ev_tdlam_before | -1.19e-07     |\n",
      "| loss_ent        | 2.145977      |\n",
      "| loss_kl         | 0.0025001206  |\n",
      "| loss_pol_entpen | -0.02145977   |\n",
      "| loss_pol_surr   | -0.0050637303 |\n",
      "| loss_vf_loss    | 27205.875     |\n",
      "-----------------------------------\n",
      "********** Iteration 13 ************\n",
      "Reward ( 3500 )\t -10.486092381992586\n",
      "TIME FOR RESET========= 4.046979904174805\n",
      "=========resetting with seed:  54552\n",
      "sending: reset\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00010 |      -0.02164 |      2.52e+04 |      1.36e-05 |       2.16427\n",
      "     -0.00093 |      -0.02163 |      2.51e+04 |       0.00012 |       2.16328\n",
      "     -0.00275 |      -0.02161 |      2.50e+04 |       0.00036 |       2.16146\n",
      "     -0.00340 |      -0.02159 |      2.49e+04 |       0.00085 |       2.15918\n",
      "Evaluating losses...\n",
      "     -0.00339 |      -0.02158 |      2.48e+04 |       0.00118 |       2.15809\n",
      "-----------------------------------\n",
      "| EpLenMean       | 499           |\n",
      "| EpRewMean       | -5.33e+03     |\n",
      "| EpThisIter      | 1             |\n",
      "| EpisodesSoFar   | 7             |\n",
      "| TimeElapsed     | 32.4          |\n",
      "| TimestepsSoFar  | 3584          |\n",
      "| ev_tdlam_before | 0.0415        |\n",
      "| loss_ent        | 2.1580925     |\n",
      "| loss_kl         | 0.0011769783  |\n",
      "| loss_pol_entpen | -0.021580927  |\n",
      "| loss_pol_surr   | -0.0033946373 |\n",
      "| loss_vf_loss    | 24845.953     |\n",
      "-----------------------------------\n",
      "********** Iteration 14 ************\n",
      "Reward ( 3750 )\t -10.880002819704032\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "    -4.67e-05 |      -0.02197 |      3.00e+04 |      5.50e-07 |       2.19718\n",
      "     -0.00030 |      -0.02197 |      2.97e+04 |      4.52e-06 |       2.19719\n",
      "     -0.00066 |      -0.02197 |      2.95e+04 |      2.24e-05 |       2.19719\n",
      "     -0.00101 |      -0.02197 |      2.92e+04 |      6.24e-05 |       2.19717\n",
      "Evaluating losses...\n",
      "     -0.00141 |      -0.02197 |      2.91e+04 |      9.88e-05 |       2.19714\n",
      "----------------------------------\n",
      "| EpLenMean       | 499          |\n",
      "| EpRewMean       | -5.33e+03    |\n",
      "| EpThisIter      | 0            |\n",
      "| EpisodesSoFar   | 7            |\n",
      "| TimeElapsed     | 32.9         |\n",
      "| TimestepsSoFar  | 3840         |\n",
      "| ev_tdlam_before | 5.96e-08     |\n",
      "| loss_ent        | 2.1971447    |\n",
      "| loss_kl         | 9.884604e-05 |\n",
      "| loss_pol_entpen | -0.021971447 |\n",
      "| loss_pol_surr   | -0.001406529 |\n",
      "| loss_vf_loss    | 29077.016    |\n",
      "----------------------------------\n",
      "********** Iteration 15 ************\n",
      "Reward ( 4000 )\t -10.880002819704032\n",
      "TIME FOR RESET========= 4.107720375061035\n",
      "=========resetting with seed:  58660\n",
      "sending: reset\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00012 |      -0.02197 |      2.66e+04 |      8.83e-07 |       2.19713\n",
      "    -5.59e-05 |      -0.02197 |      2.65e+04 |      3.63e-06 |       2.19712\n",
      "     -0.00037 |      -0.02197 |      2.63e+04 |      5.80e-06 |       2.19712\n",
      "     -0.00088 |      -0.02197 |      2.62e+04 |      1.14e-05 |       2.19713\n",
      "Evaluating losses...\n",
      "     -0.00122 |      -0.02197 |      2.61e+04 |      1.79e-05 |       2.19713\n",
      "-----------------------------------\n",
      "| EpLenMean       | 499           |\n",
      "| EpRewMean       | -5.35e+03     |\n",
      "| EpThisIter      | 1             |\n",
      "| EpisodesSoFar   | 8             |\n",
      "| TimeElapsed     | 36.6          |\n",
      "| TimestepsSoFar  | 4096          |\n",
      "| ev_tdlam_before | -1.19e-07     |\n",
      "| loss_ent        | 2.197133      |\n",
      "| loss_kl         | 1.7935352e-05 |\n",
      "| loss_pol_entpen | -0.02197133   |\n",
      "| loss_pol_surr   | -0.0012227865 |\n",
      "| loss_vf_loss    | 26072.19      |\n",
      "-----------------------------------\n",
      "********** Iteration 16 ************\n",
      "Reward ( 4250 )\t -10.880002819704032\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "    -6.64e-05 |      -0.02197 |      2.97e+04 |      6.91e-07 |       2.19714\n",
      "     -0.00049 |      -0.02197 |      2.96e+04 |      6.03e-06 |       2.19714\n",
      "     -0.00080 |      -0.02197 |      2.95e+04 |      1.80e-05 |       2.19714\n",
      "     -0.00128 |      -0.02197 |      2.94e+04 |      3.66e-05 |       2.19714\n",
      "Evaluating losses...\n",
      "     -0.00147 |      -0.02197 |      2.93e+04 |      5.02e-05 |       2.19713\n",
      "-----------------------------------\n",
      "| EpLenMean       | 499           |\n",
      "| EpRewMean       | -5.35e+03     |\n",
      "| EpThisIter      | 0             |\n",
      "| EpisodesSoFar   | 8             |\n",
      "| TimeElapsed     | 37            |\n",
      "| TimestepsSoFar  | 4352          |\n",
      "| ev_tdlam_before | -1.19e-07     |\n",
      "| loss_ent        | 2.1971285     |\n",
      "| loss_kl         | 5.024636e-05  |\n",
      "| loss_pol_entpen | -0.021971285  |\n",
      "| loss_pol_surr   | -0.0014694333 |\n",
      "| loss_vf_loss    | 29328.95      |\n",
      "-----------------------------------\n",
      "********** Iteration 17 ************\n",
      "Reward ( 4500 )\t -10.880002819704032\n",
      "TIME FOR RESET========= 4.041931867599487\n",
      "=========resetting with seed:  62702\n",
      "sending: reset\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-57b2ab5fd5b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPO1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MlpPolicy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/ppo1/pposgd_simple.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    240\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"********** Iteration %i ************\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0miters_so_far\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                     \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0;31m# Stop training early (triggered by the callback)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spinningup/lib/python3.6/site-packages/stable_baselines/common/runners.py\u001b[0m in \u001b[0;36mtraj_segment_generator\u001b[0;34m(policy, env, horizon, reward_giver, gail, callback)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mcurrent_ep_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVecEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ees-pees/backend/environment.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=========resetting with seed: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupervisor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_com\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ees-pees/backend/automate.py\u001b[0m in \u001b[0;36mreset_environment\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iiiiif'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFunctionCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sending: reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_env_reset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "time_steps = 5000\n",
    "model_name = \"Webots1\"\n",
    "\n",
    "model = PPO1(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=time_steps, log_interval=100)\n",
    "model.save(\"models/{}\".format(model_name))\n",
    "\n",
    "# model = PPO1.load(\"models/{}\".format('DQN_WebotFakeMini_TRPO_pj1_nReward2_200000'))\n",
    "# env = MyEnv()\n",
    "# obs = env.reset()\n",
    "\n",
    "# env.render()\n",
    "# done = False\n",
    "# max_num_steps = 100\n",
    "# time = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
